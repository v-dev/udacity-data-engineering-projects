{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"testing filter with multiple conditions\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all records that have none in either of userid or sesisonid fileds:\n",
    "user_log_dropna = user_log.dropna(how='any', subset=['userId', 'sessionId'])\n",
    "user_log_dropna.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# didn't filter out any... try different filter...\n",
    "user_log_valid = user_log_dropna.filter(user_log_dropna['userId'] != '')\n",
    "user_log_valid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|firstname|userid|\n",
      "+---------+------+\n",
      "|    Kelly|  1138|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's find a user who downgraded their service first...\n",
    "user_log_valid.filter(\"page = 'Submit Downgrade'\").select(['firstname', 'userid']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelly_userid = 1138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+-----+--------------------+-------------+\n",
      "|userid|firstname|    page|level|                song|           ts|\n",
      "+------+---------+--------+-----+--------------------+-------------+\n",
      "|  1138|    Kelly|    Home| paid|                null|1513729066284|\n",
      "|  1138|    Kelly|NextSong| paid| Everybody Everybody|1513729066284|\n",
      "|  1138|    Kelly|NextSong| paid|               Gears|1513729313284|\n",
      "|  1138|    Kelly|NextSong| paid|        Use Somebody|1513729552284|\n",
      "|  1138|    Kelly|NextSong| paid|Love Of My Life (...|1513729783284|\n",
      "|  1138|    Kelly|NextSong| paid|Down In The Valle...|1513730001284|\n",
      "|  1138|    Kelly|NextSong| paid|Treat Her Like A ...|1513730263284|\n",
      "|  1138|    Kelly|NextSong| paid|Everybody Thinks ...|1513730518284|\n",
      "|  1138|    Kelly|NextSong| paid|      Fourteen Wives|1513730768284|\n",
      "|  1138|    Kelly|NextSong| paid|   Love On The Rocks|1513731182284|\n",
      "|  1138|    Kelly|NextSong| paid|           Breakeven|1513731435284|\n",
      "|  1138|    Kelly|NextSong| paid|          Leaf House|1513731695284|\n",
      "|  1138|    Kelly|NextSong| paid|       NAISEN KANSSA|1513731857284|\n",
      "|  1138|    Kelly|NextSong| paid|  You're In My Heart|1513732160284|\n",
      "|  1138|    Kelly|NextSong| paid|Roll On Down The ...|1513732302284|\n",
      "|  1138|    Kelly|NextSong| paid|Plasticities (Remix)|1513732540284|\n",
      "|  1138|    Kelly|NextSong| paid|             Secrets|1513732770284|\n",
      "|  1138|    Kelly|NextSong| paid|               Hello|1513732994284|\n",
      "|  1138|    Kelly|NextSong| paid|    I Never Told You|1513733223284|\n",
      "|  1138|    Kelly|NextSong| paid|       Love Break Me|1513733456284|\n",
      "+------+---------+--------+-----+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets also show a few more interesting columns & order by...\n",
    "user_log_valid.select(['userid', 'firstname', 'page', 'level', 'song', 'ts']).where(user_log['userid']==kelly_userid).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final goal is to create a new column for a particular user based on these special events\n",
    "# let's call this column, \"phase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function which returns integer based if event was a 'downgrade'\n",
    "from pyspark.sql.types import IntegerType\n",
    "flag_downgrade_event = udf(lambda x: 1 if x == 'Submit Downgrade' else 0, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add udf to our spark dataframe\n",
    "user_log_valid = user_log_valid.withColumn('downgraded', flag_downgrade_event('page'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-------------+--------+-----+----------+\n",
      "|userid|firstname|           ts|    page|level|downgraded|\n",
      "+------+---------+-------------+--------+-----+----------+\n",
      "|  1138|    Kelly|1513729066284|    Home| paid|         0|\n",
      "|  1138|    Kelly|1513729066284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513729313284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513729552284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513729783284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513730001284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513730263284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513730518284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513730768284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513731182284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513731435284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513731695284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513731857284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513732160284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513732302284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513732540284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513732770284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513732994284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513733223284|NextSong| paid|         0|\n",
      "|  1138|    Kelly|1513733456284|NextSong| paid|         0|\n",
      "+------+---------+-------------+--------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_log_valid.select(['userid', 'firstname', 'ts', 'page', 'level', 'downgraded']).where(user_log_valid['userid'] == kelly_userid).sort('ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to see only kelly's events when her level was NOT 'paid', or 'free'\n",
    "\n",
    "how do i write it?\n",
    "take above + add 1 more condition... ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempt 1, using `and` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-90a537eb4b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_log_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'firstname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'page'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'downgraded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_log_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkelly_userid\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muser_log_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'free'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[1;32m    683\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[1;32m    684\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "user_log_valid.select(['userid', 'firstname', 'ts', 'page', 'level', 'downgraded']).where(user_log_valid['userid'] == kelly_userid and user_log_valid['level'] == 'free').sort('ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempt 2, using `&` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o107.and. Trace:\npy4j.Py4JException: Method and([class java.lang.Integer]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a4dad455030f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_log_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'firstname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'page'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'downgraded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_log_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkelly_userid\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0muser_log_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'free'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mnjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o107.and. Trace:\npy4j.Py4JException: Method and([class java.lang.Integer]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
     ]
    }
   ],
   "source": [
    "user_log_valid.select(['userid', 'firstname', 'ts', 'page', 'level', 'downgraded']).where(user_log_valid['userid'] == kelly_userid & user_log_valid['level'] == 'free').sort('ts').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attempt 3, using `&&` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-62d0e068c8ac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-62d0e068c8ac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    user_log_valid.select(['userid', 'firstname', 'ts', 'page', 'level', 'downgraded']).where(user_log_valid['userid'] == kelly_userid && user_log_valid['level'] == 'free').sort('ts').show()\u001b[0m\n\u001b[0m                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "user_log_valid.select(['userid', 'firstname', 'ts', 'page', 'level', 'downgraded']).where(user_log_valid['userid'] == kelly_userid && user_log_valid['level'] == 'free').sort('ts').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
